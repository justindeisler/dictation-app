---
phase: 02-core-recording-permissions
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - DictationApp/Sources/Services/PermissionManager.swift
  - DictationApp/Sources/Services/AudioRecorder.swift
  - DictationApp/DictationApp.xcodeproj/project.pbxproj
autonomous: true

must_haves:
  truths:
    - "App can check microphone permission status"
    - "App can request microphone permission with system dialog"
    - "App can check accessibility permission status"
    - "App can show guidance when permissions denied"
    - "App can record audio to a file in Groq-compatible format"
  artifacts:
    - path: "DictationApp/Sources/Services/PermissionManager.swift"
      provides: "Microphone and accessibility permission checking/requesting"
      min_lines: 80
      exports: ["PermissionManager", "PermissionStatus"]
    - path: "DictationApp/Sources/Services/AudioRecorder.swift"
      provides: "AVAudioRecorder wrapper for 16kHz mono WAV recording"
      min_lines: 60
      exports: ["AudioRecorder", "AudioRecorderError"]
  key_links:
    - from: "PermissionManager"
      to: "AVCaptureDevice"
      via: "authorizationStatus and requestAccess"
      pattern: "AVCaptureDevice\\.(authorizationStatus|requestAccess)"
    - from: "PermissionManager"
      to: "AXIsProcessTrusted"
      via: "accessibility permission check"
      pattern: "AXIsProcessTrusted"
    - from: "AudioRecorder"
      to: "AVAudioRecorder"
      via: "record() and stop()"
      pattern: "AVAudioRecorder\\(url:"
---

<objective>
Create PermissionManager and AudioRecorder foundation services for Phase 2 recording functionality.

Purpose: These services provide the permission checking/requesting and audio capture capabilities needed before the hotkey can trigger recording. They are standalone services with no UI dependencies.

Output: Two new service files (PermissionManager.swift, AudioRecorder.swift) integrated into the Xcode project.
</objective>

<execution_context>
@/Users/justindeisler/.claude/get-shit-done/workflows/execute-plan.md
@/Users/justindeisler/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/02-core-recording-permissions/02-RESEARCH.md
@DictationApp/Sources/Services/KeychainManager.swift
@DictationApp/Sources/Services/LoginItemManager.swift
@DictationApp/Sources/App/AppDelegate.swift
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PermissionManager service</name>
  <files>DictationApp/Sources/Services/PermissionManager.swift</files>
  <action>
Create PermissionManager.swift following the established singleton pattern with @MainActor:

1. Define PermissionStatus enum: .granted, .denied, .notDetermined

2. Create @MainActor final class PermissionManager with static shared singleton

3. Implement microphone permission methods:
   - `checkMicrophonePermission() -> PermissionStatus` using AVCaptureDevice.authorizationStatus(for: .audio)
   - `requestMicrophonePermission() async -> Bool` using AVCaptureDevice.requestAccess(for: .audio)
   - `showMicrophonePermissionGuidance()` showing NSAlert with deep link to x-apple.systempreferences:com.apple.preference.security?Privacy_Microphone

4. Implement accessibility permission methods:
   - `checkAccessibilityPermission() -> Bool` using AXIsProcessTrusted()
   - `requestAccessibilityPermission()` using AXIsProcessTrustedWithOptions with prompt option
   - `showAccessibilityPermissionGuidance()` showing NSAlert with deep link to x-apple.systempreferences:com.apple.preference.security?Privacy_Accessibility

5. Import AVFoundation for microphone APIs
6. Import ApplicationServices for accessibility APIs (AXIsProcessTrusted)
7. Import AppKit for NSAlert and NSWorkspace

Follow the guidance alert pattern from LoginItemManager.showSystemSettingsGuidance().
  </action>
  <verify>
Build with: cd DictationApp && xcodebuild -scheme DictationApp -configuration Debug build 2>&1 | grep -E "(error:|warning:|BUILD)"

Expected: BUILD SUCCEEDED with no errors in PermissionManager.swift
  </verify>
  <done>
PermissionManager.swift exists with:
- PermissionStatus enum with 3 cases
- checkMicrophonePermission() returning correct status
- requestMicrophonePermission() as async function
- checkAccessibilityPermission() returning Bool
- requestAccessibilityPermission() triggering system prompt
- Both guidance methods showing alerts with System Settings deep links
  </done>
</task>

<task type="auto">
  <name>Task 2: Create AudioRecorder service</name>
  <files>DictationApp/Sources/Services/AudioRecorder.swift, DictationApp/DictationApp.xcodeproj/project.pbxproj</files>
  <action>
Create AudioRecorder.swift following the established singleton pattern with @MainActor:

1. Import AVFoundation

2. Define AudioRecorderError enum: .invalidURL, .failedToStart, .permissionDenied (with LocalizedError conformance and errorDescription)

3. Create @MainActor final class AudioRecorder with static shared singleton

4. Private properties:
   - `recorder: AVAudioRecorder?`
   - `recordingURL: URL?`
   - `isRecording: Bool = false` (private(set))

5. Audio settings dictionary for Groq API compatibility (16kHz mono WAV):
   ```swift
   private let audioSettings: [String: Any] = [
       AVFormatIDKey: Int(kAudioFormatLinearPCM),
       AVSampleRateKey: 16000.0,
       AVNumberOfChannelsKey: 1,
       AVLinearPCMBitDepthKey: 16,
       AVLinearPCMIsFloatKey: false,
       AVLinearPCMIsBigEndianKey: false,
       AVLinearPCMIsNonInterleaved: false
   ]
   ```

6. Implement methods:
   - `startRecording() throws` - creates unique temp file path, initializes AVAudioRecorder, calls prepareToRecord() then record(), sets isRecording = true
   - `stopRecording() -> URL?` - calls stop(), sets isRecording = false, verifies file exists, returns URL

7. Use FileManager.default.temporaryDirectory for temp file storage
8. Generate unique filename with UUID: `recording-\(UUID().uuidString).wav`

After creating the file, add it to the Xcode project:
- Add AudioRecorder.swift to the Sources/Services group in project.pbxproj
- Follow the same pattern used for LoginItemManager.swift and KeychainManager.swift
  </action>
  <verify>
Build with: cd DictationApp && xcodebuild -scheme DictationApp -configuration Debug build 2>&1 | grep -E "(error:|warning:|BUILD)"

Then verify file exists and is in project:
grep -l "AudioRecorder" DictationApp/DictationApp.xcodeproj/project.pbxproj

Expected: BUILD SUCCEEDED, AudioRecorder appears in project file
  </verify>
  <done>
AudioRecorder.swift exists with:
- AudioRecorderError enum with 3 cases and LocalizedError
- audioSettings configured for 16kHz mono WAV
- startRecording() that creates temp file and starts AVAudioRecorder
- stopRecording() that returns URL of recorded file
- isRecording property tracks state
- Both new files added to Xcode project and build succeeds
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. Build succeeds: `cd DictationApp && xcodebuild -scheme DictationApp build`
2. PermissionManager.swift exists in Sources/Services/
3. AudioRecorder.swift exists in Sources/Services/
4. Both files follow @MainActor singleton pattern
5. No compiler warnings about concurrency
</verification>

<success_criteria>
- PermissionManager can check/request microphone and accessibility permissions
- AudioRecorder can create 16kHz mono WAV files in temp directory
- Both services integrated into Xcode project
- Build succeeds with no errors
- Requirements partially covered: PRM-01 (mic request), PRM-02 (accessibility request), PRM-03 (guidance), REC-04 (audio format)
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-recording-permissions/02-01-SUMMARY.md`
</output>
